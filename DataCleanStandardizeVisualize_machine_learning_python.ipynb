{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be5e7a1a7278c138e277e90b019db4961154c731"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import os\n",
    "from operator import itemgetter    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import funcsigs\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV,KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "from funcsigs import signature\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from mlxtend.preprocessing import shuffle_arrays_unison\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import models, regularizers, layers, optimizers, losses, metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import math\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "from statsmodels.formula import api\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d624986c6d662b3dec980c593981fb913cb00c01"
   },
   "outputs": [],
   "source": [
    "# read in the data\n",
    "\n",
    "df = pd.read_excel(r\"dataset.xlsx\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target and features\n",
    "\n",
    "target = 'COPD_Diagnose_ja_nein'\n",
    "features = [i for i in df.columns if i not in [target]]\n",
    "\n",
    "# make a copy of the original data\n",
    "\n",
    "original_df = df.copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show what are in the work space.\n",
    "\n",
    "dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fce3fd763d30cf516d00815bb386cd95cea14ec",
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display some data information \n",
    "\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fce3fd763d30cf516d00815bb386cd95cea14ec",
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display some data information \n",
    "\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fce3fd763d30cf516d00815bb386cd95cea14ec",
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display some data information \n",
    "\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the number of values for all columns \n",
    "\n",
    "df.nunique().sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# figure out numerical and categorical features\n",
    "\n",
    "nu = df[features].nunique().sort_values()\n",
    "nf = []; \n",
    "cf = []; \n",
    "nnf = 0; \n",
    "ncf = 0; \n",
    "\n",
    "for i in range(df[features].shape[1]):\n",
    "    if nu.values[i]<=16: \n",
    "        cf.append(nu.index[i])\n",
    "    else: nf.append(nu.index[i])\n",
    "\n",
    "print('\\n\\033[1mInference:\\033[0m The Datset has {} numerical and {} categorical features.'.format(len(nf),len(cf)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set how many numerical features and categorical features.\n",
    "\n",
    "Nnf = 13\n",
    "Ncf = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count plot for categorical features\n",
    "\n",
    "print('\\033[1mVisualising Categorical Features:'.center(100))\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 2, ncols = 3)\n",
    "ax = axs.flatten()\n",
    "for i in range(len(cf)):\n",
    "    if df[cf[i]].nunique()<=16:\n",
    "        sns.countplot(x = cf[i], data = df, ax = ax[i])\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution plot for numerical features\n",
    "\n",
    "print('\\033[1mNumeric Features Distribution'.center(130))\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 5, ncols = 3)\n",
    "ax = axs.flatten()\n",
    "for i in range(len(nf)):\n",
    "    sns.distplot(df[nf[i]], ax = ax[i], hist_kws=dict(edgecolor=\"black\", linewidth=2), bins=10)\n",
    "plt.tight_layout()\n",
    "ax[13].set_visible(False)\n",
    "ax[14].set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot for numerical features\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 5, ncols = 3)\n",
    "ax = axs.flatten()\n",
    "for i in range(len(nf)):\n",
    "    df.boxplot(nf[i], ax = ax[i])\n",
    "plt.tight_layout()\n",
    "ax[13].set_visible(False)\n",
    "ax[14].set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplots for all features \n",
    "\n",
    "g = sns.pairplot(df)\n",
    "plt.title('Pairplots for all the Feature')\n",
    "g.map_upper(sns.kdeplot, levels=4, color=\".2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the number of Null values in each feature\n",
    "\n",
    "nvc = pd.DataFrame(df.isnull().sum().sort_values(), columns=['Total Null Values'])\n",
    "nvc['Percentage'] = round(nvc['Total Null Values']/df.shape[0],3)*100\n",
    "print(nvc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review a few rows of the data\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the null values in a few features by the most frequent value in that column. \n",
    "\n",
    "df['Raceethnicity'].fillna(df['Raceethnicity'].mode()[0],inplace=True)\n",
    "df['Sex'].fillna(df['Sex'].mode()[0],inplace=True)\n",
    "df['Dentatestatus'].fillna(df['Dentatestatus'].mode()[0],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the null values in a some features by mean value.  \n",
    "\n",
    "col_to_be_imputed = ['AgeatinterviewScreener', 'PovertyIncomeRatiounimputedincome', 'Pulseratebeatsminage5years','OverallaverageK1systolicBPage5', 'OverallaverageK5diastolicBPage5', 'Bodymassindex','Upperquadrantperiodontalassessments','Lowerquadrantperiodontalassessments','SumofpermanentDMFSduetodisease','SumofpermanentDFMSduetoanycause','SumofpermanentDFMSduetoanycause','SumofpermanentDFS','SumofpermanentDMFTduetodisease','SumofpermanentDMFTduetoanycause','Bleeding_Percentage','Furcation_SUM', 'MAL']\n",
    "for item in col_to_be_imputed:\n",
    "    df[item].fillna(df[item].mean(),inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder categrical features by LabelEncoder. \n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Raceethnicity'] = le.fit_transform(df['Raceethnicity'])\n",
    "df['Sex'] = le.fit_transform(df['Sex'])\n",
    "df['Dentatestatus'] = le.fit_transform(df['Dentatestatus'])\n",
    "\n",
    "# convert other features values from float to int\n",
    "\n",
    "df['AgeatinterviewScreener'] = df['AgeatinterviewScreener'].astype(int)\n",
    "df['PovertyIncomeRatiounimputedincome'] = df['PovertyIncomeRatiounimputedincome'].astype(int)\n",
    "df['Pulseratebeatsminage5years'] = df['Pulseratebeatsminage5years'].astype(int)\n",
    "df['OverallaverageK1systolicBPage5'] = df['OverallaverageK1systolicBPage5'].astype(int)\n",
    "df['OverallaverageK5diastolicBPage5'] = df['OverallaverageK5diastolicBPage5'].astype(int)\n",
    "df['Bodymassindex'] = df['Bodymassindex'].astype(int)\n",
    "df['Upperquadrantperiodontalassessments'] = df['Upperquadrantperiodontalassessments'].astype(int)\n",
    "df['Lowerquadrantperiodontalassessments'] = df['Lowerquadrantperiodontalassessments'].astype(int)\n",
    "df['SumofpermanentDMFSduetodisease'] = df['SumofpermanentDMFSduetodisease'].astype(int)\n",
    "df['SumofpermanentDFMSduetoanycause'] = df['SumofpermanentDFMSduetoanycause'].astype(int)\n",
    "df['SumofpermanentDFMSduetoanycause'] = df['SumofpermanentDFMSduetoanycause'].astype(int)\n",
    "df['SumofpermanentDFS'] = df['SumofpermanentDFS'].astype(int)\n",
    "df['SumofpermanentDMFTduetodisease'] = df['SumofpermanentDMFTduetodisease'].astype(int)\n",
    "df['SumofpermanentDMFTduetoanycause'] = df['SumofpermanentDMFTduetoanycause'].astype(int)\n",
    "df['Bleeding_Percentage'] = df['Bleeding_Percentage'].astype(int)\n",
    "df['Furcation_SUM'] = df['Furcation_SUM'].astype(int)\n",
    "df['MAL'] = df['MAL'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display information of all features. \n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove some useless features. \n",
    "\n",
    "df_feat = df.drop(['Raceethnicity','Sex','Dentatestatus','COPD_Diagnose_ja_nein'],axis=1)\n",
    "\n",
    "# get labels for each sample.\n",
    "\n",
    "target =  pd.get_dummies(df[['COPD_Diagnose_ja_nein']],drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels for each categrical feature. \n",
    "\n",
    "dummies = pd.get_dummies(df[['Raceethnicity','Sex','Dentatestatus', ]],drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a few rows of the useful features. \n",
    "\n",
    "df_feat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize all features data by sklearn StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_feat)\n",
    "df_scaled = scaler.transform(df_feat)\n",
    "df_scaled = pd.DataFrame(df_scaled,columns=df_feat.columns[:19])\n",
    "df_preprocessed = pd.concat([df_scaled,dummies,target], axis=1)\n",
    "df_preprocessed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show number of features and number of samples\n",
    "\n",
    "print('\\n\\033[1mInference:\\033[0m The Datset consists of {} features & {} samples.'.format(df_preprocessed.shape[1], df_preprocessed.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see summarize of feature values\n",
    "\n",
    "df_preprocessed.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "798b9834d32ba534e5aca36d5763b9624fe00565"
   },
   "outputs": [],
   "source": [
    "# set y (values to be predicted), and X (feature values)\n",
    "\n",
    "y = df_preprocessed['COPD_Diagnose_ja_nein']\n",
    "X = df_preprocessed.drop('COPD_Diagnose_ja_nein', axis = 1)\n",
    "\n",
    "print(\"y - Labels\", y.shape)\n",
    "print(\"X - N Label N id \", X.shape)\n",
    "print(X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60be44d230f432f3f087f15a238feb21deb68bbf"
   },
   "outputs": [],
   "source": [
    "# review the shapes of data frames\n",
    "\n",
    "print(df_preprocessed.shape)\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aefe400392c73d77e55bf9f2410e7b725df2e77c"
   },
   "outputs": [],
   "source": [
    "# separate data to Tain or Test.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "print ('X_train: ', X_train.shape)\n",
    "print ('X_test: ', X_test.shape)\n",
    "print ('y_train: ', y_train.shape)\n",
    "print ('y_test: ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a few of y values\n",
    "\n",
    "y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f03ccf0923716b07035356abcf3acb4a51d23025"
   },
   "outputs": [],
   "source": [
    "# perform logistic regression, RandomForest, SGD classify, KNN, Decision tree, Gaussian Naive Bayes, and SVM by 5-fold cross validation and show accuracy\n",
    "\n",
    "seed = 42\n",
    "scoring = 'roc_auc' \n",
    "\n",
    "Mymodels = []\n",
    "Mymodels.append(('LogReg', LogisticRegression()))\n",
    "Mymodels.append(('RandomForestClassifier', RandomForestClassifier()))\n",
    "Mymodels.append(('SGDclassifier', SGDClassifier()))\n",
    "Mymodels.append(('KNearestNeighbors', KNeighborsClassifier()))\n",
    "Mymodels.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n",
    "Mymodels.append(('GaussianNB', GaussianNB()))\n",
    "Mymodels.append(('SVM', SVC()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in Mymodels:\n",
    "    kfold = model_selection.KFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e0d67a66679ee59af083b102408c69db5646ba33"
   },
   "outputs": [],
   "source": [
    "# evaluate RandomForest model by multiple hyper parameters. \n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "#param_grid = [{},]\n",
    "Param_grid = {'n_estimators':[100, 200, 300], 'max_depth':[None, 5, 10], 'max_features':['auto', 'sqrt', 'log2']}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid = Param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5a406c3bcd3c161727af4b5dcab74dca35daf853"
   },
   "outputs": [],
   "source": [
    "# define a random forest model\n",
    "\n",
    "model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b9097a12c41f10f3b86e0915577ce0d781e4758c"
   },
   "outputs": [],
   "source": [
    "# fit the random forest model and extract feature importance.\n",
    "\n",
    "trainFinalFI = X\n",
    "yFinalFI = y\n",
    "\n",
    "model.fit(trainFinalFI,yFinalFI)\n",
    "\n",
    "FI_model = pd.DataFrame({\"Feature Importance\":model.feature_importances_,}, index=trainFinalFI.columns)\n",
    "FI_model[FI_model[\"Feature Importance\"] > 0.005].sort_values(\"Feature Importance\").plot(kind=\"barh\",figsize=(15,25))\n",
    "plt.xticks(rotation=90)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "49522e46d392dfcf95d60a54481d1dce22cdef30"
   },
   "outputs": [],
   "source": [
    "# print feature importance values. \n",
    "\n",
    "FI_model = pd.DataFrame({\"Feature Importance\":model.feature_importances_,}, index=trainFinalFI.columns)\n",
    "FI_model=FI_model.sort_values('Feature Importance', ascending = False)\n",
    "print(FI_model[FI_model[\"Feature Importance\"] > 0.001])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e4dc0ce72a8131e32acda585f4b76061034f7f0"
   },
   "outputs": [],
   "source": [
    "# define a function for plotting learning curve. \n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 10)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = 1-np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = 1-np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "afe92f8617e5290fc0317d2331947583282bac65"
   },
   "outputs": [],
   "source": [
    "# plot the learning curve for the random forest model\n",
    "\n",
    "title = \"Learning Curves \"\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2)\n",
    "plot_learning_curve(model, title, X_train, y_train, cv=cv, n_jobs=4)\n",
    "plot_learning_curve(model, title, X, y, ylim=(0.01, 0.99), cv=cv, n_jobs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91574fedd82e85ae7d616e23f4c5174213926f24"
   },
   "outputs": [],
   "source": [
    "# prepare train data and test data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print ('X_train: ', X_train.shape)\n",
    "print ('X_test: ', X_test.shape)\n",
    "print ('y_train: ', y_train.shape)\n",
    "print ('y_test: ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3c18714aca39c174cd2c2d747f3ee23c2491362"
   },
   "outputs": [],
   "source": [
    "# apply the random forest model and compute confusion matrix. \n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "final_predictions = model.predict(X_test)\n",
    "\n",
    "conf_mx = confusion_matrix(y_test, final_predictions)\n",
    "print('conf_mx ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f5410cd3c3f20bbee11842580a4cb0fb828b883"
   },
   "outputs": [],
   "source": [
    "# define a function for plot confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(cm,target_names,title='Confusion Matrix',cmap=None,\n",
    "                          normalize=False):\n",
    "    import itertools\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9c064c815e2cb9ca1fa26681cc8d68998571911a"
   },
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "\n",
    "plot_confusion_matrix(conf_mx, \n",
    "                      normalize    = False,\n",
    "                      target_names = [0,1],\n",
    "                      title        = \"Confusion Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "837aba4cbecd2bde6bdaab1cb8417348ee823dea"
   },
   "outputs": [],
   "source": [
    "# compute more parameters, such as accuracy, recall, precision, F1Score.\n",
    "\n",
    "NumClasses = 2\n",
    "\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for z in range(NumClasses):\n",
    "# One class at a time - calculate confusion matrix\n",
    "    SumCM = np.sum(conf_mx)\n",
    "    TPz = conf_mx[z,z]\n",
    "    FNz = np.sum(conf_mx[z,:], axis=0) -TPz\n",
    "    FPz = np.sum(conf_mx[:,z], axis=0) -TPz\n",
    "    TNz = SumCM - (TPz+FNz+FPz)\n",
    "    #FPz = np.sum(conf_mx[z], axis=-1) \n",
    "    #FPz = sum(conf_mx(:, z))-conf_mx(z, z)\n",
    "    #FNz = sum(conf_mx(x, :), 2)-conf_mx(x, x)\n",
    "    print('Class ',z)\n",
    "  \n",
    "\n",
    "    # Create conf matrix for class z\n",
    "    cmZ = np.zeros([2, 2], dtype=np.int32)\n",
    "    cmZ[0,0] = TNz\n",
    "    cmZ[0,1] = FPz\n",
    "    cmZ[1,0] = FNz\n",
    "    cmZ[1,1] = TPz\n",
    "\n",
    "    plot_confusion_matrix(cmZ, \n",
    "                          normalize    = False,\n",
    "                          target_names = [0,1],\n",
    "                          title        = \"Confusion matrix for one class \")\n",
    "\n",
    "    accuracy = (TPz+TNz)/(TPz+TNz+FPz+FNz)\n",
    "    recall = TPz/(TPz+FNz)\n",
    "    precision = TPz/(TPz+FPz)\n",
    "    f1score = 2*recall*precision/(recall+precision)\n",
    "    #roc_auc = auc(FPz, TPz)\n",
    "    \n",
    "    print('TPz ',TPz)\n",
    "    print('FNz ',FNz)\n",
    "    print('FPz ',FPz)\n",
    "    print('TNz ',TNz)\n",
    "    print('sum ', TPz+TNz+FPz+FNz)\n",
    "    print(cmZ)\n",
    "    print('Sum of CM ', np.sum(cmZ))\n",
    "    print ('accuracy ',round(accuracy,4))\n",
    "    print('recall ', round(recall,4))\n",
    "    print('precision ', round(precision,4))\n",
    "    print('F1Score ', round(f1score,4))\n",
    "    print('-'*40)\n",
    "    \n",
    "    TP = TP + TPz\n",
    "    TN = TN + TNz\n",
    "    FP = FP + FPz\n",
    "    FN = FN + FNz\n",
    "print ('TN: ', TN)\n",
    "print ('FP: ', FP)\n",
    "print ('FN: ', FN)\n",
    "print ('TP: ', TP)\n",
    "print('_'*40)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "27853b996b38fbcf56419a7c9963410928055e53"
   },
   "source": [
    "**NN model**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "201db6f9eb3432ad3e76948f1343d507d5176e46"
   },
   "outputs": [],
   "source": [
    "# prepare train data, test data for neural network model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print ('X_train: ', X_train.shape)\n",
    "print ('X_test: ', X_test.shape)\n",
    "print ('y_train: ', y_train.shape)\n",
    "print ('y_test: ', y_test.shape)\n",
    "\n",
    "print(y_train)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b45ff6a343f8e9b8a2400dadc703d7cd62a2add"
   },
   "outputs": [],
   "source": [
    "\n",
    "x_val = X_test\n",
    "partial_x_train = X_train\n",
    "y_val = y_test\n",
    "partial_y_train = y_train\n",
    "\n",
    "print(\"partial_x_train \", partial_x_train.shape)\n",
    "print(\"partial_y_train \", partial_y_train.shape)\n",
    "\n",
    "print(\"x_val \", x_val.shape)\n",
    "print(\"y_val \", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a4761290ca85629cb95e98fdfc0fefbed0aa871"
   },
   "outputs": [],
   "source": [
    "\n",
    "yTrain = to_categorical(partial_y_train)\n",
    "yVal = to_categorical(y_val)\n",
    "print(yTrain.shape)\n",
    "print(yVal.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "330a7c3a8a64fc1d079c0367bec4437723aca5a0"
   },
   "outputs": [],
   "source": [
    "# build neural network model\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(19,)))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "# FIT/TRAIN model\n",
    "\n",
    "NumEpochs = 20\n",
    "BatchSize = 128\n",
    "lr=1e-4\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['categorical_accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "history = model.fit(partial_x_train, yTrain, epochs=NumEpochs, batch_size=BatchSize, validation_data=(x_val, yVal))\n",
    "\n",
    "results = model.evaluate(x_val, yVal)\n",
    "print(\"_\"*100)\n",
    "print(\"Test Loss and Accuracy\")\n",
    "print(\"results \", results)\n",
    "history_dict = history.history\n",
    "history_dict.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model by validation data\n",
    "\n",
    "evalu = model.evaluate(x_val, yVal)\n",
    "print(model.metrics_names)\n",
    "print(evalu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c50e9f8b3702332944a2bf4157152474824538d"
   },
   "outputs": [],
   "source": [
    "# plot VALIDATION LOSS curves\n",
    "\n",
    "plt.clf()\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, (len(history_dict['loss']) + 1))\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot VALIDATION ACCURACY curves\n",
    "\n",
    "plt.clf()\n",
    "acc_values = history_dict['categorical_accuracy']\n",
    "val_acc_values = history_dict['val_categorical_accuracy']\n",
    "epochs = range(1, (len(history_dict['categorical_accuracy']) + 1))\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb2fa916bc883388474a2649dad790dc5c651c79"
   },
   "outputs": [],
   "source": [
    "# Final Fit / Predict\n",
    "\n",
    "final_predictions = model.predict(x_val)\n",
    "print(final_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7abb85e63a2b8b176b98f9b47b66a122459b75dc"
   },
   "outputs": [],
   "source": [
    "# PREDICT & ARGMAX to get the digit from the probability of softmax layer\n",
    "\n",
    "print(final_predictions)\n",
    "pred = []\n",
    "numTest = final_predictions.shape[0]\n",
    "for i in range(numTest):\n",
    "    pred.append(np.argmax(final_predictions[i])) \n",
    "predictions = np.array(pred)  \n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "602525e0e93d979636c69eef688c292644e8dcb4"
   },
   "outputs": [],
   "source": [
    "# PREDICT & ARGMAX to get the digit from the probability of softmax layer\n",
    "\n",
    "print(yVal)\n",
    "pred = []\n",
    "numTest = yVal.shape[0]\n",
    "for i in range(numTest):\n",
    "    pred.append(np.argmax(yVal[i])) \n",
    "yValNum = np.array(pred)  \n",
    "print(yValNum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f3de9b05c64e6084885d86ec7b285c101155532"
   },
   "outputs": [],
   "source": [
    "# compute confusion_matrix\n",
    "\n",
    "conf_mx = confusion_matrix(yValNum, predictions)\n",
    "print('conf_mx ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "074d2939a86c28ee1e5f47de485dc3357c89686a"
   },
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "\n",
    "plot_confusion_matrix(conf_mx, \n",
    "                      normalize    = False,\n",
    "                      target_names = [0,1],\n",
    "                      title        = \"Confusion Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d48f5ba2f3b10a78d85214d0626c8ecd1f637a8b"
   },
   "outputs": [],
   "source": [
    "# compute AUC ROC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "        lb = LabelBinarizer()\n",
    "        lb.fit(y_test)\n",
    "        y_test = lb.transform(y_test)\n",
    "        y_pred = lb.transform(y_pred)\n",
    "        return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "print('AUC ROC ',multiclass_roc_auc_score(yValNum, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "30231eece09b4e58137f7de92a1edff1ce67d1eb6dc3e77c83046d0c2c0004f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
